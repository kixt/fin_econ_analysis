{\rtf1\ansi\ansicpg1252\cocoartf2509
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs26 \cf0 I\'d88304 Financial Econometrics Analysis
\f1\b0\fs24 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b \cf0 Notes
\f1\b0 \
Thore Petersen\
\
09.10.19\
- implemented ARCH(q) estimation in Julia and tested/established connection to R via XRJulia\
- tested own implementation against tseries::garch() in R: parameter estimates match up to 2-4 decimal points; tested against R implementation of likelihood, value in optimum matches too\
- R too slow for numerical operation (by factor >10^3 compared to Julia), so implement QMLE optimisation in Julia, and connect via XRJulia to be able to do data prep etc in R\
- conditional mean process just in two step procedure? i.e. first estimate Y_t = phi * Y_t-1 + X_t, extract X_t and model it as ARCH with X_t = sigma_t * epsilon_t?\
- to-do: \
	- implement SWARCH(K, q)\
\
- SWARCH estimation not trivial, estimation of Markov part tricky\
\
10.10.19\
- SWARCH prone to overfitting says Sjur\
- sensible diagnostic for adequacy should be volatility clustering/breaks in ARCH residuals\
- alternative: estimate GARCH and then some hidden Markov model on estimated volatility to identify normal/crisis periods\
\
18.10.19\
- resort to using rugarch implementation in R, together with copula package\
- problem of identifying high volatility periods, difficult to model Markov process w/o changes in parameters of underlying model -> nothing to estimate\
	- either with fixed date or some threshold; probably fixed date for financial crisis}